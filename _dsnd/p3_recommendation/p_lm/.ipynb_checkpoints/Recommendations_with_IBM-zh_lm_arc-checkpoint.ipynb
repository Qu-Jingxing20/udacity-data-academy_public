{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM 推荐系统\n",
    "\n",
    "在此 notebook 中，你将运用所学的推荐技能处理 IBM Watson Studio 平台的真实数据。 \n",
    "\n",
    "\n",
    "你可以通过此 workspace 提交 notebook，或者在本地机器上操作并在下个页面提交 notebook。无论是哪种方式，都请确保代码符合项目[审阅标准](https://review.udacity.com/#!/rubrics/2632/view)。**请定期保存代码。**\n",
    "\n",
    "跟着目录操作，你将能够创建多个不同的推荐方法，这些方法可以用于不同的情形。 \n",
    "\n",
    "\n",
    "# 目录\n",
    "\n",
    "I. [探索性数据分析](#Exploratory-Data-Analysis)<br>\n",
    "II.[基于排名的推荐方法](#Rank)<br>\n",
    "III.[基于用户-用户的协同过滤](#User-User)<br>\n",
    "IV.[基于内容的推荐方法（选修内容）](#Content-Recs)<br>\n",
    "V. [矩阵分解](#Matrix-Fact)<br>\n",
    "VI.[其他内容和总结](#conclusions)\n",
    "\n",
    "你可以在 notebook 的结尾处找到提交 notebook 的指南。首先导入必要的库并读取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / Prepare\n",
    "### // load env and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:18.957044Z",
     "start_time": "2019-09-19T07:44:16.731638Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "## import basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "## import ml libs\n",
    "\n",
    "## import specific func\n",
    "import project_tests as t\n",
    "\n",
    "## set warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## set paras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.168543Z",
     "start_time": "2019-09-19T07:44:18.960348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((45993, 3), (1056, 5))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# snip data\n",
    "display(df.head(1))\n",
    "display(df_content.head(1))\n",
    "df.shape, df_content.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### // alter data types\n",
    "- id liked should be str type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.243176Z",
     "start_time": "2019-09-19T07:44:19.172265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45993 entries, 0 to 45992\n",
      "Data columns (total 3 columns):\n",
      "article_id    45993 non-null object\n",
      "title         45993 non-null object\n",
      "email         45976 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# change id liked column to str\n",
    "df.article_id = df.article_id.astype(int).astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### // check detail on str column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.251767Z",
     "start_time": "2019-09-19T07:44:19.246630Z"
    }
   },
   "outputs": [],
   "source": [
    "# check more detail on str column\n",
    "## check1\n",
    "#pprint(df_content.doc_body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.265485Z",
     "start_time": "2019-09-19T07:44:19.254424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Detect bad readings in real time using Python and Streaming Analytics.'\n",
      "'Detect Malfunctioning IoT Sensors with Streaming Analytics'\n",
      "('using pixiedust for fast, flexible, and easier data analysis and '\n",
      " 'experimentation')\n"
     ]
    }
   ],
   "source": [
    "## check2\n",
    "pprint(df_content.doc_description[0])\n",
    "pprint(df_content.doc_full_name[0])\n",
    "pprint(df.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">第一部分：探索性数据分析</a>\n",
    "\n",
    "通过以下字典和单元格了解数据的描述性统计信息。\n",
    "\n",
    "`1.` 用户与数据集中的多少篇文章互动了？分布如何？以图表的形式描述每个用户与某篇文章互动的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.290735Z",
     "start_time": "2019-09-19T07:44:19.267955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pre - del na\n",
    "print(df.shape[0])\n",
    "df.dropna(inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.301572Z",
     "start_time": "2019-09-19T07:44:19.293974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45976"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1a user - article iteration times\n",
    "df.article_id.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.629637Z",
     "start_time": "2019-09-19T07:44:19.306888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 1b hist for article usage\n",
    "pd.Series.hist(df.article_id.value_counts(),bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.665904Z",
     "start_time": "2019-09-19T07:44:19.636373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1c max useage (by user)\n",
    "## -updated \n",
    "article_byuser = df.groupby('email')['article_id'].count()\n",
    "article_byuser.max()\n",
    "## arc for only for max useage by article\n",
    "#df.article_id.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.691115Z",
     "start_time": "2019-09-19T07:44:19.668757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1d median of article usage\n",
    "#df.article_id.value_counts().median()\n",
    "## -updated- should groupby on user (email)\n",
    "df.groupby('email')['article_id'].count().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T02:59:30.618142Z",
     "start_time": "2019-09-17T02:59:30.609942Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.698468Z",
     "start_time": "2019-09-19T07:44:19.693926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "median_val = 3 # 50% of individuals interact with ____ number of articles or fewer.\n",
    "max_views_by_user = 364 # The maximum number of user-article interactions by any 1 user is ______."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 发现并移除 **df_content** dataframe 中的重复文章。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.711870Z",
     "start_time": "2019-09-19T07:44:19.701985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 1056)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete duplicates\n",
    "## compare unique and numbers\n",
    "df_content.doc_full_name.nunique(), df_content.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.744033Z",
     "start_time": "2019-09-19T07:44:19.714621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...</td>\n",
       "      <td>Upgrading your PostgreSQL deployment to versio...</td>\n",
       "      <td>Upgrading your PostgreSQL to 9.5</td>\n",
       "      <td>Live</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>* Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...</td>\n",
       "      <td>Kaggle is your home for data science. Learn ne...</td>\n",
       "      <td>Data Science Bowl 2017</td>\n",
       "      <td>Live</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Maureen McElaney Blocked Unblock Follow Follow...</td>\n",
       "      <td>There’s a reason you’ve been hearing a lot abo...</td>\n",
       "      <td>Bridging the Gap Between Python and Scala Jupy...</td>\n",
       "      <td>Live</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>We've always considered MySQL as a potential C...</td>\n",
       "      <td>Compose for MySQL now for you</td>\n",
       "      <td>Live</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Homepage Follow Sign in / Sign up * Home\\r\\n *...</td>\n",
       "      <td>It has never been easier to build AI or machin...</td>\n",
       "      <td>The Greatest Public Datasets for AI – Startup ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...</td>\n",
       "      <td>Lua is a compact language which can be embedde...</td>\n",
       "      <td>A Speed Guide To Redis Lua Scripting</td>\n",
       "      <td>Live</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1051</td>\n",
       "      <td>PouchDB-find is a new API and syntax that allo...</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>A look under the covers of PouchDB-find</td>\n",
       "      <td>Live</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1052</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>A comparison of logistic regression and naive ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1053</td>\n",
       "      <td>Essays about data, building products and boots...</td>\n",
       "      <td>In order to demystify some of the magic behind...</td>\n",
       "      <td>What I Learned Implementing a Classifier from ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Once you get used to developing in a Notebook ...</td>\n",
       "      <td>Jupyter Notebooks with Scala, Python, or R Ker...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_body  \\\n",
       "6     UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...   \n",
       "8     * Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...   \n",
       "13    Maureen McElaney Blocked Unblock Follow Follow...   \n",
       "17    Enterprise Pricing Articles Sign in Free 30-Da...   \n",
       "18    Homepage Follow Sign in / Sign up * Home\\r\\n *...   \n",
       "...                                                 ...   \n",
       "1050  lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...   \n",
       "1051  PouchDB-find is a new API and syntax that allo...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  Essays about data, building products and boots...   \n",
       "1055  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "\n",
       "                                        doc_description  \\\n",
       "6     Upgrading your PostgreSQL deployment to versio...   \n",
       "8     Kaggle is your home for data science. Learn ne...   \n",
       "13    There’s a reason you’ve been hearing a lot abo...   \n",
       "17    We've always considered MySQL as a potential C...   \n",
       "18    It has never been easier to build AI or machin...   \n",
       "...                                                 ...   \n",
       "1050  Lua is a compact language which can be embedde...   \n",
       "1051  PouchDB uses MapReduce as its default search m...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  In order to demystify some of the magic behind...   \n",
       "1055  Once you get used to developing in a Notebook ...   \n",
       "\n",
       "                                          doc_full_name doc_status  article_id  \n",
       "6                      Upgrading your PostgreSQL to 9.5       Live           6  \n",
       "8                                Data Science Bowl 2017       Live           8  \n",
       "13    Bridging the Gap Between Python and Scala Jupy...       Live          13  \n",
       "17                        Compose for MySQL now for you       Live          17  \n",
       "18    The Greatest Public Datasets for AI – Startup ...       Live          18  \n",
       "...                                                 ...        ...         ...  \n",
       "1050               A Speed Guide To Redis Lua Scripting       Live        1045  \n",
       "1051            A look under the covers of PouchDB-find       Live        1046  \n",
       "1052  A comparison of logistic regression and naive ...       Live        1047  \n",
       "1053  What I Learned Implementing a Classifier from ...       Live        1048  \n",
       "1055  Jupyter Notebooks with Scala, Python, or R Ker...       Live        1050  \n",
       "\n",
       "[834 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## snip duplicated\n",
    "df_content[df.duplicated(['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.758797Z",
     "start_time": "2019-09-19T07:44:19.747845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056, 5)\n",
      "(1051, 5)\n"
     ]
    }
   ],
   "source": [
    "# remove any rows that have the same article_id - only keep the first\n",
    "print(df_content.shape)\n",
    "df_content.drop_duplicates(subset = 'article_id', inplace=True)\n",
    "print(df_content.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` 在以下单元格中查找：\n",
    "\n",
    "**a.**用户与之互动的唯一文章数量。  \n",
    "**b.**数据集中的唯一文章数量（无论用户是否与之互动了）。<br>\n",
    "**c.**数据集中的唯一用户数量。（不包括空值）<br>\n",
    "**d.**数据集中的用户-文章互动次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.782591Z",
     "start_time": "2019-09-19T07:44:19.761839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 714, 714)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "series = df.article_id.value_counts()\n",
    "len(series[series == 1]), len(series[series >= 1]), series.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.796812Z",
     "start_time": "2019-09-19T07:44:19.785497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "df.article_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.814539Z",
     "start_time": "2019-09-19T07:44:19.799861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c\n",
    "## drop na already done at the beginning (17 null at email)\n",
    "df.email.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.872295Z",
     "start_time": "2019-09-19T07:44:19.817520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45976, 45976)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d solution, df.shape\n",
    "## 剔除 email 为空的, 再对 article_id 进行value count 求和\n",
    "## 实际上只有 email 有17个空值\n",
    "## s1\n",
    "df.article_id.value_counts().sum()\n",
    "## 开始傻掉了,这里就应该是去除空值之后的行数(每行代表一次互动)\n",
    "## s2\n",
    "df.shape[0], df.email.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.880081Z",
     "start_time": "2019-09-19T07:44:19.875171Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_articles = 714 # The number of unique articles that have at least one interaction\n",
    "total_articles = 1051 # The number of unique articles on the IBM platform\n",
    "unique_users = 5148 # The number of unique users\n",
    "user_article_interactions = 45993 # The number of user-article interactions\n",
    "#user_article_interactions = 45976 # The number of user-article interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 在以下单元格中查找查看次数最多的文章的 **article_id**，以及被查看频率。在与公司领导讨论后，`email_mapper` 函数被视为将用户映射到 ID 的合理方式。有少数几个空值，并且所有这些空值都可能属于一个用户（我们以这种方式使用以下函数存储了这些值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.901277Z",
     "start_time": "2019-09-19T07:44:19.884007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1429', 937)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_series = df.article_id.value_counts()\n",
    "email_series.index[0], email_series[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.919071Z",
     "start_time": "2019-09-19T07:44:19.904358Z"
    }
   },
   "outputs": [],
   "source": [
    "s = df.article_id.value_counts()\n",
    "most_viewed_article_id = '1429.0' # The most viewed article in the dataset as a string with one value following the decimal \n",
    "max_views = 937 # The most viewed article in the dataset was viewed how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.965268Z",
     "start_time": "2019-09-19T07:44:19.921379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1314</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1429</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1338</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1276</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  user_id\n",
       "0       1430  using pixiedust for fast, flexible, and easier...        1\n",
       "1       1314       healthcare python streaming application demo        2\n",
       "2       1429         use deep learning for image classification        3\n",
       "3       1338          ml optimization using cognitive assistant        4\n",
       "4       1276          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.979231Z",
     "start_time": "2019-09-19T07:44:19.972376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)\n",
    "\n",
    "# Warning! \n",
    "## 一些值是在非清理na和重复时候得出的, 具体更新过程写在了前面代码框中了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Rank\">第二部分：基于排名的推荐方法</a>\n",
    "\n",
    "与之前的课程不同，我们没有关于用户是否喜欢某篇文章的评分。我们只知道用户与文章互动了。在这些情形下，文章的热门程度只能通过用户与文章的互动频率来判断。\n",
    "\n",
    "`1.` 填写以下函数，使其返回前 **n** 篇文章，按照互动次数从高到低排序。使用以下测试测试你的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:19.996890Z",
     "start_time": "2019-09-19T07:44:19.984679Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    top_articles = df.article_id.value_counts()[n]\n",
    "    \n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    top_articles = df.article_id.value_counts().index[n]\n",
    " \n",
    "    return top_articles # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.024632Z",
     "start_time": "2019-09-19T07:44:20.000280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n",
      "1436\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.355829Z",
     "start_time": "2019-09-19T07:44:20.027926Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-318025fef7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Test each of your three lists from above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msol_2_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_top_articles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/udacity-private/_dsnd/p3_recommendation/p_lm/project_tests.py\u001b[0m in \u001b[0;36msol_2_test\u001b[0;34m(top_articles)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mchecks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'top_5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top_10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"{}.p\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your {} looks like the solution list! Nice job.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"User-User\">第三部分：基于用户-用户的协同过滤</a>\n",
    "\n",
    "\n",
    "`1.` 使用以下函数调整 **df** dataframe 的形状，使行表示用户，并使列表示文章。  \n",
    "\n",
    "* 每个**用户**只能在每**行**中出现一次。\n",
    "\n",
    "\n",
    "* 每篇**文章**只能在每**列**中出现一次。  \n",
    "\n",
    "\n",
    "* **如果用户与某篇文章互动了，则在该文章所在的列与用户行形成的单元格中填充 1**。无论用户与文章互动了多少次，都填充 1。  \n",
    "\n",
    "\n",
    "* **如果用户与文章没有互动，则在该文章所在的列与用户行形成的单元格中填充 0**。 \n",
    "\n",
    "使用以下测试检验矩阵的基本结构是否与解答中的结构一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.366452Z",
     "start_time": "2019-09-19T07:44:16.837Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Fill in the function here\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.368384Z",
     "start_time": "2019-09-19T07:44:16.841Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 完成以下函数，该函数应该接受 user_id，并提供与该用户最相似的有序用户列表（从最相似到最不相似）。返回的列表不应包含提供的 user_id，因为我们知道每个用户都与其本身相似。因为每个用户的结果是二元的，所以建议用两个用户的点积表示相似性。 \n",
    "\n",
    "使用测试测试你的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.370875Z",
     "start_time": "2019-09-19T07:44:16.845Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "\n",
    "    # sort by similarity\n",
    "\n",
    "    # create list of just the ids\n",
    "   \n",
    "    # remove the own user's id\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.372607Z",
     "start_time": "2019-09-19T07:44:16.848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` 创建了为每个用户提供最相似用户的函数后，你需要使用这些用户查找可以推荐的文章。完成以下函数，以返回向每个用户推荐的文章。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.374973Z",
     "start_time": "2019-09-19T07:44:16.852Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return recs # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.376712Z",
     "start_time": "2019-09-19T07:44:16.856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.378169Z",
     "start_time": "2019-09-19T07:44:16.859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 现在我们将提高上述 **user_user_recs** 函数的一致性。  \n",
    "\n",
    "* 当所有用户与给定用户的邻近程度都一样时，我们并非随意选择用户，而是先选择总互动次数最多的用户，然后选择互动次数第二多的用户。\n",
    "\n",
    "\n",
    "* 当推荐的文章数量以低于 m 的数字开始并以高于 m的数字结束时，我们并非随意选择文章，而是先选择总互动次数最多的文章，然后选择总互动次数第二多的文章。你可以利用之前编写的 **top_articles** 函数获得这种排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.384069Z",
     "start_time": "2019-09-19T07:44:16.863Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.387463Z",
     "start_time": "2019-09-19T07:44:16.866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` 请利用上述函数正确填写以下字典。然后对照解答检验该字典。按照以下注释提供必要的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.389673Z",
     "start_time": "2019-09-19T07:44:16.870Z"
    }
   },
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "user1_most_sim = # Find the user that is most similar to user 1 \n",
    "user131_10th_sim = # Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.392517Z",
     "start_time": "2019-09-19T07:44:16.873Z"
    }
   },
   "outputs": [],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` 如果是新用户，你可以使用上述哪个函数做出推荐？请解释。你能想到更好的推荐方法吗？在以下单元格中解释向新用户做出推荐的更好方法。\n",
    "\n",
    "**请在此处填写答案。**\n",
    "\n",
    "`7.` 利用现有函数向以下新用户提供前 10 篇推荐文章。你可以对照我们的解答测试你的函数，确保在如何做出推荐方面与我们的想法一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.395376Z",
     "start_time": "2019-09-19T07:44:16.877Z"
    }
   },
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = # Your recommendations here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.398963Z",
     "start_time": "2019-09-19T07:44:16.880Z"
    }
   },
   "outputs": [],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Content-Recs\">第四部分：基于内容的推荐方法（选修内容）</a>\n",
    "\n",
    "另一种推荐方法是对与某个术语相关的文章进行从高到低排名。内容可以是 **doc_body**、**doc_description** 或**doc_full_name**。创建基于内容的推荐系统并非只有一种方式，尤其是考虑到每列都包含与内容相关的信息。  \n",
    "\n",
    "`1.` 使用以下函数主体创建一个基于内容的推荐系统。由于这个推荐系统的正确答案不止一个，所以没有提供测试函数。如果你想尝试一种需要更多输入值的方法，可以更改函数输入。当前的输入值考虑到了你可能会使用基于内容的推荐方法。此外，你可能会使用满足“内容标准”的最热门推荐方法，总之，你在做出这些推荐时可以灵活选择方法。\n",
    "\n",
    "### 这部分并非通过项目必须完成的任务。但是，你可以借机展示你的技能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.401309Z",
     "start_time": "2019-09-19T07:44:16.883Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_content_recs():\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 你已经创建了基于内容的推荐系统，接着在以下单元格中简要说明下这一基于内容的推荐系统是如何运行的。你觉得你的函数有哪些值得改进的地方吗？这一基于内容的推荐系统有什么新奇的地方吗？\n",
    "\n",
    "### 这部分并非通过项目必须完成的任务。但是，你可以借机展示你的技能。\n",
    "\n",
    "**在此处解释下这一基于内容的推荐系统。**\n",
    "\n",
    "`3.` 根据注释使用这一基于内容的推荐系统对以下情形做出推荐。我们没有提供测试，因为在创建此基于内容的推荐系统时，可以有多个正确答案。\n",
    "\n",
    "### 这部分并非通过项目必须完成的任务。但是，你可以借机展示你的技能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.403529Z",
     "start_time": "2019-09-19T07:44:16.887Z"
    }
   },
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Matrix-Fact\">第五部分：矩阵分解</a>\n",
    "\n",
    "在此部分，你将利用矩阵分解向 IBM Watson Studio 平台上的用户推荐文章。\n",
    "\n",
    "`1.` 你在上述**第三部分**的**第一个问题**中已经创建了 **user_item** 矩阵。接下来的第一个问题需要你运行单元格，为**第五部分**的其他步骤做好准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.406125Z",
     "start_time": "2019-09-19T07:44:16.890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.408814Z",
     "start_time": "2019-09-19T07:44:16.894Z"
    }
   },
   "outputs": [],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 在此部分，你可以对用户-项目矩阵运用[numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) 的奇异值分解方法。在单元格中执行 SVD，并解释为何与课程中的步骤不一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.411167Z",
     "start_time": "2019-09-19T07:44:16.897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = # use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在此处填写答案。**\n",
    "\n",
    "`3.` 如何确定潜在特征的数量？这个问题比较难。运行以下单元格后你会发现，随着潜在特征数量的增加，用户-项目矩阵中 1 和 0 值的预测错误率会降低。运行以下单元格，了解当潜在特征的数量增加时，准确率会如何提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.413412Z",
     "start_time": "2019-09-19T07:44:16.901Z"
    }
   },
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 通过上述单元格，我们无法判断要使用多少个潜在特征，因为能够更好地预测矩阵的 1 和 0 值，并不表明我们就能做出很好的推荐。我们可以将数据集划分为训练集和测试集，如以下单元格所示。  \n",
    "\n",
    "根据第三个问题的代码判断，不同的潜在特征数量对训练集和测试集的准确率有何影响。使用以下划分方法： \n",
    "\n",
    "* 我们可以对测试集中的多少个用户做出预测？  \n",
    "* 由于冷启动问题，我们无法对多少个用户做出预测？\n",
    "* 我们可以对测试集中的多少篇文章做出预测？  \n",
    "* 由于冷启动问题，我们无法对多少篇文章做出预测？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.415859Z",
     "start_time": "2019-09-19T07:44:16.904Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.418523Z",
     "start_time": "2019-09-19T07:44:16.908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': # letter here, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': # letter here, \n",
    "    'How many articles can we make predictions for in the test set?': # letter here,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?': # letter here\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` 现在对上述 **user_item_train** 数据集进行奇异值分解，并得出 U、S 和 V 转置矩阵。然后判断在使用不同的潜在特征数量时，可以使用此矩阵分解方法对 **user_item_test** 数据集中的多少行做出预测，并根据测试数据的准确率确定应该保留多少个潜在特征。这个问题需要运用在第 `2` - `4`.个问题中完成的步骤。\n",
    "\n",
    "通过以下单元格了解 SVD 在测试数据上做出推荐预测的效果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.420850Z",
     "start_time": "2019-09-19T07:44:16.911Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = # fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T07:44:20.423387Z",
     "start_time": "2019-09-19T07:44:16.914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` 在以下单元格中解释上个问题的结果。根据你得出的结果，讨论下你会如何判断上述推荐系统是否比用户目前查找文章的方式更好。 \n",
    "\n",
    "**请在此处填写答案。**\n",
    "\n",
    "<a id='conclusions'></a>\n",
    "## 其他内容\n",
    "你现在可以保存为每个用户推荐的文章，开发一个类来作出新的预测并更新结果，以及创建一个部署结果的应用。这些任务并不是此项目必须完成的任务。但是，在学完课程知识后，你肯定能够继续完成这些任务并改进你的项目。\n",
    "\n",
    "\n",
    "# 总结\n",
    "\n",
    "> 恭喜！你已经完成 IBM 推荐系统项目。 \n",
    "\n",
    "> **小贴士**：当你对项目满意后，请检查报告并看看是否满足所有[审阅标准](https://review.udacity.com/#!/rubrics/2632/view)。请删除所有的**小贴士**（例如上方小贴士），使演示尽可能流畅。\n",
    "\n",
    "\n",
    "# 提交指南\n",
    "\n",
    "> 在提交项目之前，你需要在 workspace 的此部分创建 notebook 的 .html 或 .pdf 版本。运行以下单元格即可创建这两种版本。如果操作正确，系统会返回代码 0，并且你可以在 workspace 目录（点击左上角的橙色 Jupyter 图标）中看到生成的 .html 文件。\n",
    "\n",
    "> 或者，你可以通过**文件** > **下载为**子菜单将此报告下载为 .html 文件，然后手动将报告上传到 workspace 目录中：点击左上角的橙色 Jupyter 图标，然后点击“上传”按钮。\n",
    "\n",
    "> 完成这些步骤后，你可以点击右下角的“提交项目”按钮，提交项目。这样便会创建和提交一个 zip 文件，其中包含此 .ipynb 文件和你创建的 .html 或 .pdf 文件。恭喜！ \n",
    "\n",
    "\n",
    "```python\n",
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
