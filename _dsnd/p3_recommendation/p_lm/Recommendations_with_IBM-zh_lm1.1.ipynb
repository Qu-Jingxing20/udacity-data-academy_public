{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM 推荐系统\n",
    "\n",
    "在此 notebook 中，你将运用所学的推荐技能处理 IBM Watson Studio 平台的真实数据。 \n",
    "\n",
    "\n",
    "你可以通过此 workspace 提交 notebook，或者在本地机器上操作并在下个页面提交 notebook。无论是哪种方式，都请确保代码符合项目[审阅标准](https://review.udacity.com/#!/rubrics/2632/view)。**请定期保存代码。**\n",
    "\n",
    "跟着目录操作，你将能够创建多个不同的推荐方法，这些方法可以用于不同的情形。 \n",
    "\n",
    "\n",
    "# 目录\n",
    "\n",
    "I. [探索性数据分析](#Exploratory-Data-Analysis)<br>\n",
    "II.[基于排名的推荐方法](#Rank)<br>\n",
    "III.[基于用户-用户的协同过滤](#User-User)<br>\n",
    "IV.[基于内容的推荐方法（选修内容）](#Content-Recs)<br>\n",
    "V. [矩阵分解](#Matrix-Fact)<br>\n",
    "VI.[其他内容和总结](#conclusions)\n",
    "\n",
    "你可以在 notebook 的结尾处找到提交 notebook 的指南。首先导入必要的库并读取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / Prepare\n",
    "### // load env and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:04.843603Z",
     "start_time": "2019-09-20T03:36:04.837619Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "## import basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "## import ml libs\n",
    "\n",
    "## import specific func\n",
    "import project_tests as t\n",
    "\n",
    "## set warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## set paras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.005172Z",
     "start_time": "2019-09-20T03:36:04.844609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((45993, 3), (1056, 5))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# snip data\n",
    "display(df.head(1))\n",
    "display(df_content.head(1))\n",
    "df.shape, df_content.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### // alter data types\n",
    "- id liked should be str type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T02:28:03.375519Z",
     "start_time": "2019-09-22T02:28:03.338109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45993 entries, 0 to 45992\n",
      "Data columns (total 3 columns):\n",
      "article_id    45993 non-null object\n",
      "title         45993 non-null object\n",
      "user_id       45993 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# change id liked column to str\n",
    "df.article_id = df.article_id.astype(int).astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### // check detail on str column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.050051Z",
     "start_time": "2019-09-20T03:36:05.046062Z"
    }
   },
   "outputs": [],
   "source": [
    "# check more detail on str column\n",
    "## check1\n",
    "#pprint(df_content.doc_body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.061021Z",
     "start_time": "2019-09-20T03:36:05.052046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Detect bad readings in real time using Python and Streaming Analytics.'\n",
      "'Detect Malfunctioning IoT Sensors with Streaming Analytics'\n",
      "('using pixiedust for fast, flexible, and easier data analysis and '\n",
      " 'experimentation')\n"
     ]
    }
   ],
   "source": [
    "## check2\n",
    "pprint(df_content.doc_description[0])\n",
    "pprint(df_content.doc_full_name[0])\n",
    "pprint(df.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">第一部分：探索性数据分析</a>\n",
    "\n",
    "通过以下字典和单元格了解数据的描述性统计信息。\n",
    "\n",
    "`1.` 用户与数据集中的多少篇文章互动了？分布如何？以图表的形式描述每个用户与某篇文章互动的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.078974Z",
     "start_time": "2019-09-20T03:36:05.062019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45976"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pre - del na\n",
    "print(df.shape[0])\n",
    "df.dropna(inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.085955Z",
     "start_time": "2019-09-20T03:36:05.080968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45976"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1a user - article iteration times\n",
    "df.article_id.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.293427Z",
     "start_time": "2019-09-20T03:36:05.086952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 1b hist for article usage\n",
    "pd.Series.hist(df.article_id.value_counts(),bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.308360Z",
     "start_time": "2019-09-20T03:36:05.294404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1c max useage (by user)\n",
    "## -updated \n",
    "article_byuser = df.groupby('email')['article_id'].count()\n",
    "article_byuser.max()\n",
    "## arc for only for max useage by article\n",
    "#df.article_id.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.330302Z",
     "start_time": "2019-09-20T03:36:05.309358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1d median of article usage\n",
    "#df.article_id.value_counts().median()\n",
    "## -updated- should groupby on user (email)\n",
    "df.groupby('email')['article_id'].count().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.335317Z",
     "start_time": "2019-09-20T03:36:05.332296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "median_val = 3 # 50% of individuals interact with ____ number of articles or fewer.\n",
    "max_views_by_user = 364 # The maximum number of user-article interactions by any 1 user is ______."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 发现并移除 **df_content** dataframe 中的重复文章。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.345279Z",
     "start_time": "2019-09-20T03:36:05.336331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 1056)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete duplicates\n",
    "## compare unique and numbers\n",
    "df_content.doc_full_name.nunique(), df_content.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.371192Z",
     "start_time": "2019-09-20T03:36:05.348254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...</td>\n",
       "      <td>Upgrading your PostgreSQL deployment to versio...</td>\n",
       "      <td>Upgrading your PostgreSQL to 9.5</td>\n",
       "      <td>Live</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>* Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...</td>\n",
       "      <td>Kaggle is your home for data science. Learn ne...</td>\n",
       "      <td>Data Science Bowl 2017</td>\n",
       "      <td>Live</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maureen McElaney Blocked Unblock Follow Follow...</td>\n",
       "      <td>There’s a reason you’ve been hearing a lot abo...</td>\n",
       "      <td>Bridging the Gap Between Python and Scala Jupy...</td>\n",
       "      <td>Live</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>We've always considered MySQL as a potential C...</td>\n",
       "      <td>Compose for MySQL now for you</td>\n",
       "      <td>Live</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Homepage Follow Sign in / Sign up * Home\\r\\n *...</td>\n",
       "      <td>It has never been easier to build AI or machin...</td>\n",
       "      <td>The Greatest Public Datasets for AI – Startup ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>It is often useful to use RStudio for one piec...</td>\n",
       "      <td>Working interactively with RStudio and noteboo...</td>\n",
       "      <td>Live</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Raj Singh Blocked Unblock Follow Following Dev...</td>\n",
       "      <td>You’re doing your data a disservice if you don...</td>\n",
       "      <td>Mapping for Data Science with PixieDust and Ma...</td>\n",
       "      <td>Live</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE CONVERSATIONAL INTERFACE IS THE NEW PARADI...</td>\n",
       "      <td>Botkit provides a simple framework to handle t...</td>\n",
       "      <td>The Conversational Interface is the New Paradigm</td>\n",
       "      <td>Live</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GOOGLE RESEARCH BLOG The latest news from Rese...</td>\n",
       "      <td>Much of driving is spent either stuck in traff...</td>\n",
       "      <td>Using Machine Learning to predict parking diff...</td>\n",
       "      <td>Live</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>This talk assumes you have a basic understandi...</td>\n",
       "      <td>Getting The Best Performance With PySpark</td>\n",
       "      <td>Live</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Steve Moore ...</td>\n",
       "      <td>Machine learning has already extended into so ...</td>\n",
       "      <td>Top 10 Machine Learning Use Cases: Part 1</td>\n",
       "      <td>Live</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Nick Kasten Blocked Unblock Follow Following C...</td>\n",
       "      <td>In this article, I’ll describe an app I built ...</td>\n",
       "      <td>Gaze Into My Reddit Crystal Ball – IBM Watson ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Jump to navigation\\r\\n\\r\\n * Twitter\\r\\n * Lin...</td>\n",
       "      <td>Here’s a quick and handy guide to creating dat...</td>\n",
       "      <td>Data visualization playbook: The right level o...</td>\n",
       "      <td>Live</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>* R Views\\r\\n * About this Blog\\r\\n * Contribu...</td>\n",
       "      <td>Our app will be simple in that it displays pri...</td>\n",
       "      <td>Pulling and Displaying ETF Data</td>\n",
       "      <td>Live</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TL;DR: It's easy to customise the Mongo shell'...</td>\n",
       "      <td>It's easy to customize the Mongo shell's promp...</td>\n",
       "      <td>Customizing MongoDB’s Shell with Compact Prompts</td>\n",
       "      <td>Live</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Build a custom library for Apache® Spark™ and ...</td>\n",
       "      <td>Build a custom library for Apache® Spark™ and ...</td>\n",
       "      <td>Start Developing with Spark and Notebooks</td>\n",
       "      <td>Live</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Follow Sign in / Sign up Home About Insight Da...</td>\n",
       "      <td>Community Detection at Scale</td>\n",
       "      <td>Graph-based machine learning</td>\n",
       "      <td>Live</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>* United States\\r\\n\\r\\nIBM® * Site map\\r\\n\\r\\n...</td>\n",
       "      <td>Watch how to build a storefront web app with I...</td>\n",
       "      <td>Build an app using IBM Graph</td>\n",
       "      <td>Live</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Homepage Follow Sign in Get started Homepage *...</td>\n",
       "      <td>Starting today, users will be able to access S...</td>\n",
       "      <td>Introducing Streams Designer</td>\n",
       "      <td>Live</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PREDICT FLIGHT DELAYS WITH APACHE SPARK MLLIB,...</td>\n",
       "      <td>Build a Machine Learning model with Apache Spa...</td>\n",
       "      <td>Predict Flight Delays with Apache Spark MLLib,...</td>\n",
       "      <td>Live</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>01. Holden Karau, IBM, Visits #theCUBE!. (00:2...</td>\n",
       "      <td>Advancements in the Spark Community</td>\n",
       "      <td>Live</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Homepage PUBLISHED IN AUTONOMOUS AGENTS — #AI ...</td>\n",
       "      <td>Let’s say you have the gift of flight (or you ...</td>\n",
       "      <td>How to tame the valley — Hessian-free hacks fo...</td>\n",
       "      <td>Live</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RStudio Blog * Home\\r\\n\\r\\n * Subscribe to fee...</td>\n",
       "      <td>readr 1.0.0 is now available on CRAN. readr ma...</td>\n",
       "      <td>readr 1.0.0</td>\n",
       "      <td>Live</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>METRICS MAVEN: WINDOW FUNCTIONS IN POSTGRESQL\\...</td>\n",
       "      <td>If you use PostgreSQL, you're probably already...</td>\n",
       "      <td>Metrics Maven: Window Functions in PostgreSQL</td>\n",
       "      <td>Live</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>KDNUGGETS\\r\\nData Mining, Analytics, Big Data,...</td>\n",
       "      <td>An introductory overview of NumPy, one of the ...</td>\n",
       "      <td>An Introduction to Scientific Python (and a Bi...</td>\n",
       "      <td>Live</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>Bradley Holt, IBM Cloudant Web and mobile apps...</td>\n",
       "      <td>Offline-First Apps with PouchDB</td>\n",
       "      <td>Live</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (September 27, 2016)</td>\n",
       "      <td>Live</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video provides a tour of the Community se...</td>\n",
       "      <td>Tour the Community in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (May 16, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>This video shows you how to a Cloudant Geospat...</td>\n",
       "      <td>See how a Cloudant Geospatial index is used in...</td>\n",
       "      <td>Tutorial: How to Cloudant Geospatial in Action</td>\n",
       "      <td>Live</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>We're hiring! | Blog Home * Blog Home\\r\\n * Le...</td>\n",
       "      <td>An introduction to Pandas. A quick start guide...</td>\n",
       "      <td>The pandas Data Analysis Library</td>\n",
       "      <td>Live</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Skip to contentParallelDots\\r\\n\\r\\nBlog\\r\\n\\r\\...</td>\n",
       "      <td>What exact skills do companies look for when t...</td>\n",
       "      <td>7 types of job profiles that makes you a Data ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>EMARSYS – MAKING THE MOST OF COMPOSE\\r\\nShare ...</td>\n",
       "      <td>we take a look at long-time Compose customer, ...</td>\n",
       "      <td>Emarsys – Making the Most of Compose</td>\n",
       "      <td>Live</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>Varun Singh, a software engineer at IBM's Wats...</td>\n",
       "      <td>Redis and MongoDB in the biomedical domain</td>\n",
       "      <td>Live</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video shows you how to create and adminis...</td>\n",
       "      <td>Create and administer a data catalog using IBM...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Follow Sign in / Sign up * Home\\r\\n * About In...</td>\n",
       "      <td>Audio super-resolution aims to reconstruct a h...</td>\n",
       "      <td>Using Deep Learning to Reconstruct High-Resolu...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Since then, this metric has been ubiquitously ...</td>\n",
       "      <td>Data tidying in Data Science Experience</td>\n",
       "      <td>Live</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Develop in the cloud at the click of a button!...</td>\n",
       "      <td>Build a word game app and see how to manage an...</td>\n",
       "      <td>Build a simple word game app using Cloudant on...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>BLAZINGLY FAST GEOSPATIAL QUERIES WITH REDIS\\r...</td>\n",
       "      <td>Use Redis and and Python scripts to speed your...</td>\n",
       "      <td>Blazingly Fast Geospatial Queries with Redis</td>\n",
       "      <td>Live</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>Blog Home Dataquest.io Learn Data Science in Y...</td>\n",
       "      <td>In this post, you’ll learn to query, update, a...</td>\n",
       "      <td>Working with SQLite Databases using Python and...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>DATALAYER: MANAGING (OR NOT) THE DATA IN IMMUT...</td>\n",
       "      <td>Adron Hall of Thrashing Code and Home Depot, t...</td>\n",
       "      <td>DataLayer Conference: Managing (or not) the Da...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Skip to contentWin-Vector Blog\\r\\n\\r\\nThe Win-...</td>\n",
       "      <td>Describes the use of Laplace noise in machine ...</td>\n",
       "      <td>Laplace noising versus simulated out of sample...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>This work is licensed under a Creative Commons...</td>\n",
       "      <td>A full guide to Elasticsearch, the real-time d...</td>\n",
       "      <td>The Definitive Guide</td>\n",
       "      <td>Live</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>See how quick and easy it is to set up a dashD...</td>\n",
       "      <td>Get started with dashDB on Bluemix</td>\n",
       "      <td>Live</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>The Many Flavors of NoSQL at That Conference</td>\n",
       "      <td>Live</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Skip to main content IBM developerWorks / Deve...</td>\n",
       "      <td>Building your first data warehouse doesn’t hav...</td>\n",
       "      <td>Your First Data Warehouse Is Easy. Meet the ODS.</td>\n",
       "      <td>Live</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Skip to contentDinesh Nirmal's Blog\\r\\n\\r\\nA b...</td>\n",
       "      <td>In my last blog “Business differentiation thro...</td>\n",
       "      <td>Machine Learning for the Enterprise.</td>\n",
       "      <td>Live</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Compose The Compose logo Articles Sign in Free...</td>\n",
       "      <td>MongoDB's aggregation pipeline makes finding d...</td>\n",
       "      <td>Finding Duplicate Documents in MongoDB</td>\n",
       "      <td>Live</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>MENU\\r\\nClose\\r\\nSubscribe SubscribeREDUCING O...</td>\n",
       "      <td>Nothing spoils a plot like (too much) data.</td>\n",
       "      <td>Reducing overplotting in scatterplots</td>\n",
       "      <td>Live</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Homepage IBM Watson Data Lab Follow Sign in / ...</td>\n",
       "      <td>Getting started with custom visualizations, si...</td>\n",
       "      <td>You Too Can Make Magic (in Jupyter Notebooks w...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>How I Stopped Worrying &amp; Learned to Love the M...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>Margriet Groenendijk Blocked Unblock Follow Fo...</td>\n",
       "      <td>Last week I attended the GeoPython conference ...</td>\n",
       "      <td>Mapping All the Things with Python – IBM Watso...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>In this post, we will go through how to read a...</td>\n",
       "      <td>Use IBM Data Science Experience to Read and Wr...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n...</td>\n",
       "      <td>As more devices become internet enabled, harne...</td>\n",
       "      <td>Use IoT data in Streams Designer for billing a...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>* \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r...</td>\n",
       "      <td>Continuing my previous work on exploring Arlin...</td>\n",
       "      <td>Mapping Points with Folium</td>\n",
       "      <td>Live</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...</td>\n",
       "      <td>Lua is a compact language which can be embedde...</td>\n",
       "      <td>A Speed Guide To Redis Lua Scripting</td>\n",
       "      <td>Live</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>PouchDB-find is a new API and syntax that allo...</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>A look under the covers of PouchDB-find</td>\n",
       "      <td>Live</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>A comparison of logistic regression and naive ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Essays about data, building products and boots...</td>\n",
       "      <td>In order to demystify some of the magic behind...</td>\n",
       "      <td>What I Learned Implementing a Classifier from ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Once you get used to developing in a Notebook ...</td>\n",
       "      <td>Jupyter Notebooks with Scala, Python, or R Ker...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_body  \\\n",
       "6     UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...   \n",
       "8     * Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...   \n",
       "13    Maureen McElaney Blocked Unblock Follow Follow...   \n",
       "17    Enterprise Pricing Articles Sign in Free 30-Da...   \n",
       "18    Homepage Follow Sign in / Sign up * Home\\r\\n *...   \n",
       "...                                                 ...   \n",
       "1050  lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...   \n",
       "1051  PouchDB-find is a new API and syntax that allo...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  Essays about data, building products and boots...   \n",
       "1055  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "\n",
       "                                        doc_description  \\\n",
       "6     Upgrading your PostgreSQL deployment to versio...   \n",
       "8     Kaggle is your home for data science. Learn ne...   \n",
       "13    There’s a reason you’ve been hearing a lot abo...   \n",
       "17    We've always considered MySQL as a potential C...   \n",
       "18    It has never been easier to build AI or machin...   \n",
       "...                                                 ...   \n",
       "1050  Lua is a compact language which can be embedde...   \n",
       "1051  PouchDB uses MapReduce as its default search m...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  In order to demystify some of the magic behind...   \n",
       "1055  Once you get used to developing in a Notebook ...   \n",
       "\n",
       "                                          doc_full_name doc_status  article_id  \n",
       "6                      Upgrading your PostgreSQL to 9.5       Live           6  \n",
       "8                                Data Science Bowl 2017       Live           8  \n",
       "13    Bridging the Gap Between Python and Scala Jupy...       Live          13  \n",
       "17                        Compose for MySQL now for you       Live          17  \n",
       "18    The Greatest Public Datasets for AI – Startup ...       Live          18  \n",
       "...                                                 ...        ...         ...  \n",
       "1050               A Speed Guide To Redis Lua Scripting       Live        1045  \n",
       "1051            A look under the covers of PouchDB-find       Live        1046  \n",
       "1052  A comparison of logistic regression and naive ...       Live        1047  \n",
       "1053  What I Learned Implementing a Classifier from ...       Live        1048  \n",
       "1055  Jupyter Notebooks with Scala, Python, or R Ker...       Live        1050  \n",
       "\n",
       "[834 rows x 5 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## snip duplicated\n",
    "df_content[df.duplicated(['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.378174Z",
     "start_time": "2019-09-20T03:36:05.372189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056, 5)\n",
      "(1051, 5)\n"
     ]
    }
   ],
   "source": [
    "# remove any rows that have the same article_id - only keep the first\n",
    "print(df_content.shape)\n",
    "df_content.drop_duplicates(subset = 'article_id', inplace=True)\n",
    "print(df_content.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` 在以下单元格中查找：\n",
    "\n",
    "**a.**用户与之互动的唯一文章数量。  \n",
    "**b.**数据集中的唯一文章数量（无论用户是否与之互动了）。<br>\n",
    "**c.**数据集中的唯一用户数量。（不包括空值）<br>\n",
    "**d.**数据集中的用户-文章互动次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.394131Z",
     "start_time": "2019-09-20T03:36:05.379171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 714, 714)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "series = df.article_id.value_counts()\n",
    "len(series[series == 1]), len(series[series >= 1]), series.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.406099Z",
     "start_time": "2019-09-20T03:36:05.395128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "df.article_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.419066Z",
     "start_time": "2019-09-20T03:36:05.407096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c\n",
    "## drop na already done at the beginning (17 null at email)\n",
    "df.email.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.430035Z",
     "start_time": "2019-09-20T03:36:05.420062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45976, 45976)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d solution, df.shape\n",
    "## 剔除 email 为空的, 再对 article_id 进行value count 求和\n",
    "## 实际上只有 email 有17个空值\n",
    "## s1\n",
    "df.article_id.value_counts().sum()\n",
    "## 开始傻掉了,这里就应该是去除空值之后的行数(每行代表一次互动)\n",
    "## s2\n",
    "df.shape[0], df.email.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.438015Z",
     "start_time": "2019-09-20T03:36:05.433028Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_articles = 714 # The number of unique articles that have at least one interaction\n",
    "total_articles = 1051 # The number of unique articles on the IBM platform\n",
    "unique_users = 5148 # The number of unique users\n",
    "user_article_interactions = 45993 # The number of user-article interactions\n",
    "#user_article_interactions = 45976 # The number of user-article interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 在以下单元格中查找查看次数最多的文章的 **article_id**，以及被查看频率。在与公司领导讨论后，`email_mapper` 函数被视为将用户映射到 ID 的合理方式。有少数几个空值，并且所有这些空值都可能属于一个用户（我们以这种方式使用以下函数存储了这些值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.451976Z",
     "start_time": "2019-09-20T03:36:05.440009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1429', 937)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_series = df.article_id.value_counts()\n",
    "email_series.index[0], email_series[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.463945Z",
     "start_time": "2019-09-20T03:36:05.452973Z"
    }
   },
   "outputs": [],
   "source": [
    "s = df.article_id.value_counts()\n",
    "most_viewed_article_id = '1429.0' # The most viewed article in the dataset as a string with one value following the decimal \n",
    "max_views = 937 # The most viewed article in the dataset was viewed how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.494861Z",
     "start_time": "2019-09-20T03:36:05.464942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  user_id\n",
       "0       1430  using pixiedust for fast, flexible, and easier...        1\n",
       "1       1314       healthcare python streaming application demo        2\n",
       "2       1429         use deep learning for image classification        3\n",
       "3       1338          ml optimization using cognitive assistant        4\n",
       "4       1276          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.500847Z",
     "start_time": "2019-09-20T03:36:05.495859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)\n",
    "\n",
    "# Warning! \n",
    "## 一些值是在非清理na和重复时候得出的, 具体更新过程写在了前面代码框中了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Rank\">第二部分：基于排名的推荐方法</a>\n",
    "\n",
    "与之前的课程不同，我们没有关于用户是否喜欢某篇文章的评分。我们只知道用户与文章互动了。在这些情形下，文章的热门程度只能通过用户与文章的互动频率来判断。\n",
    "\n",
    "`1.` 填写以下函数，使其返回前 **n** 篇文章，按照互动次数从高到低排序。使用以下测试测试你的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.516803Z",
     "start_time": "2019-09-20T03:36:05.501843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1429', '1330', '1431', '1427', '1364', '1314', '1293', '1170', '1162',\n",
      "       '1304'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10 Tips On Using Jupyter Notebook',\n",
       " 'Working With Notebooks In Dsx',\n",
       " 'Times World University Ranking Analysis',\n",
       " 'Rapidly Build Machine Learning Flows With Dsx',\n",
       " 'Jupyter Notebook Tutorial',\n",
       " 'Deep Learning From Scratch I: Computational Graphs',\n",
       " 'Analyze Accident Reports On Amazon Emr Spark',\n",
       " 'Ml Optimization Using Cognitive Assistant',\n",
       " 'Apache Spark Lab, Part 2: Querying Data',\n",
       " 'Putting A Human Face On Machine Learning']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing bloc\n",
    "# identicle with Part I\n",
    "top_articles_id = df.article_id.value_counts().index[:10]\n",
    "print(top_articles_id)\n",
    "list(df.iloc[top_articles_id]['title'].str.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T23:47:32.093021Z",
     "start_time": "2019-09-21T23:47:32.088034Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    top_articles_id = df.article_id.value_counts().index[:n]\n",
    "    ## assert need unchaged title\n",
    "    #top_articles = list(df.iloc[top_articles_id]['title'].str.title())\n",
    "    #top_articles = list(df.iloc[top_articles_id]['title'])\n",
    "    ## upper code give a diff result, later figure out why it happens\n",
    "    top_articles = df[df['article_id'].isin(top_articles_id)]['title'].unique().tolist()\n",
    "    \n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "# strange funtion, repeate of the upper one\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles' id\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    # top_articles_id = df.article_id.value_counts().index[:n]\n",
    "    top_articles_id = df.article_id.value_counts().index[:n].tolist()\n",
    "    \n",
    "    return top_articles_id # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T23:47:32.589774Z",
     "start_time": "2019-09-21T23:47:32.575811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'visualize car data with brunel', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'visualize car data with brunel', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'visualize car data with brunel', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'visualize car data with brunel', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'visualize car data with brunel', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'healthcare python streaming application demo', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'visualize car data with brunel', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'healthcare python streaming application demo', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use deep learning for image classification', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'visualize car data with brunel', 'visualize car data with brunel', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'healthcare python streaming application demo', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'visualize car data with brunel', 'use deep learning for image classification', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'insights from new york car accident reports', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'insights from new york car accident reports', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use deep learning for image classification', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'use deep learning for image classification', 'finding optimal locations of new store using decision optimization', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'visualize car data with brunel', 'use deep learning for image classification', 'visualize car data with brunel', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'use deep learning for image classification', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'predicting churn with the spss random tree algorithm', 'finding optimal locations of new store using decision optimization', 'finding optimal locations of new store using decision optimization', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'visualize car data with brunel', 'visualize car data with brunel', 'use deep learning for image classification', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use deep learning for image classification', 'use deep learning for image classification', 'visualize car data with brunel', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'visualize car data with brunel', 'finding optimal locations of new store using decision optimization', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'healthcare python streaming application demo', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'gosales transactions for logistic regression model', 'analyze energy consumption in buildings', 'analyze energy consumption in buildings', 'use deep learning for image classification', 'analyze energy consumption in buildings', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'visualize car data with brunel', 'visualize car data with brunel', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'healthcare python streaming application demo', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'insights from new york car accident reports', 'insights from new york car accident reports', 'visualize car data with brunel', 'insights from new york car accident reports']\n",
      "[1429.0, 1330.0, 1431.0, 1427.0, 1364.0, 1314.0, 1293.0, 1170.0, 1162.0, 1304.0]\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T23:47:03.942796Z",
     "start_time": "2019-09-21T23:47:03.909864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"User-User\">第三部分：基于用户-用户的协同过滤</a>\n",
    "\n",
    "\n",
    "`1.` 使用以下函数调整 **df** dataframe 的形状，使行表示用户，并使列表示文章。  \n",
    "\n",
    "* 每个**用户**只能在每**行**中出现一次。\n",
    "\n",
    "\n",
    "* 每篇**文章**只能在每**列**中出现一次。  \n",
    "\n",
    "\n",
    "* **如果用户与某篇文章互动了，则在该文章所在的列与用户行形成的单元格中填充 1**。无论用户与文章互动了多少次，都填充 1。  \n",
    "\n",
    "\n",
    "* **如果用户与文章没有互动，则在该文章所在的列与用户行形成的单元格中填充 0**。 \n",
    "\n",
    "使用以下测试检验矩阵的基本结构是否与解答中的结构一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.656430Z",
     "start_time": "2019-09-20T03:36:05.581630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df reload\n",
    "## for template do not cleaning enough\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.743596Z",
     "start_time": "2019-09-20T03:36:05.657427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>43.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">5143</th>\n",
       "      <th>485.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <th>270.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5145</th>\n",
       "      <th>20.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">5146</th>\n",
       "      <th>142.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <th>233.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <th>1160.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <th>16.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title\n",
       "user_id article_id       \n",
       "1       43.0            1\n",
       "        109.0           1\n",
       "        151.0           1\n",
       "        268.0           1\n",
       "        310.0           2\n",
       "...                   ...\n",
       "5146    1394.0          1\n",
       "        1416.0          1\n",
       "5147    233.0           1\n",
       "5148    1160.0          1\n",
       "5149    16.0            1\n",
       "\n",
       "[33682 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5140</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5149 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "1              NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2              NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3              NaN     NaN     NaN     NaN     NaN     1.0     NaN     NaN   \n",
       "4              NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5              NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "5145           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5146           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5147           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5148           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5149           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "article_id  16.0    18.0    ...  1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                     ...                                           \n",
       "1              NaN     NaN  ...     NaN     NaN     1.0     NaN     1.0   \n",
       "2              NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "3              NaN     NaN  ...     NaN     NaN     1.0     NaN     NaN   \n",
       "4              NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "5              NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "...            ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "5145           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "5146           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "5147           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "5148           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "5149           1.0     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "1              NaN     NaN     NaN     NaN     NaN  \n",
       "2              NaN     NaN     NaN     NaN     NaN  \n",
       "3              NaN     NaN     NaN     NaN     NaN  \n",
       "4              NaN     NaN     NaN     NaN     NaN  \n",
       "5              NaN     NaN     NaN     NaN     NaN  \n",
       "...            ...     ...     ...     ...     ...  \n",
       "5145           NaN     NaN     NaN     NaN     NaN  \n",
       "5146           NaN     NaN     NaN     NaN     NaN  \n",
       "5147           NaN     NaN     NaN     NaN     NaN  \n",
       "5148           NaN     NaN     NaN     NaN     NaN  \n",
       "5149           NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5149 rows x 714 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test code\n",
    "display(df.groupby(['user_id','article_id']).count())\n",
    "display(df.groupby(['user_id','article_id'])['title'].count().unstack())\n",
    "# maybe get_dummies is more efficient, test later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.749580Z",
     "start_time": "2019-09-20T03:36:05.744594Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Fill in the function here\n",
    "    df_temp = df.copy()\n",
    "    user_item = df_temp.groupby(['user_id','article_id'])['title'].count().unstack()\n",
    "    \n",
    "    user_item.fillna(0, inplace=True)\n",
    "    \n",
    "    return user_item # return the user_item matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:05.855835Z",
     "start_time": "2019-09-20T03:36:05.750578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "1              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3              0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "4              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  16.0    18.0    ...  1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                     ...                                           \n",
       "1              0.0     0.0  ...     0.0     0.0     1.0     0.0     1.0   \n",
       "2              0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "3              0.0     0.0  ...     0.0     0.0     1.0     0.0     0.0   \n",
       "4              0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5              0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "1              0.0     0.0     0.0     0.0     0.0  \n",
       "2              0.0     0.0     0.0     0.0     0.0  \n",
       "3              0.0     0.0     0.0     0.0     0.0  \n",
       "4              0.0     0.0     0.0     0.0     0.0  \n",
       "5              0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item = create_user_item_matrix(df)\n",
    "user_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.325548Z",
     "start_time": "2019-09-20T03:36:05.856801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5149, 714), (4048, 714), 47.0, 47.0)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can only get 47 for last questions\n",
    "user_item.shape, user_item.drop_duplicates().shape, user_item.sum(axis=1)[1], user_item.drop_duplicates().sum(axis=1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T01:51:51.100482Z",
     "start_time": "2019-09-18T01:51:51.091076Z"
    }
   },
   "source": [
    "### /Question1/ \n",
    "I can not run through this test last question, need instructions, thanks!\n",
    "- my value is 47\n",
    "- assert want 36\n",
    "- solution code are above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.330534Z",
     "start_time": "2019-09-20T03:36:06.326545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "# for pass the code make 3rd assert as note\n",
    "\n",
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "#assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 完成以下函数，该函数应该接受 user_id，并提供与该用户最相似的有序用户列表（从最相似到最不相似）。返回的列表不应包含提供的 user_id，因为我们知道每个用户都与其本身相似。因为每个用户的结果是二元的，所以建议用两个用户的点积表示相似性。 \n",
    "\n",
    "使用测试测试你的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.443234Z",
     "start_time": "2019-09-20T03:36:06.331532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "1              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  16.0    18.0    ...  1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                     ...                                           \n",
       "1              0.0     0.0  ...     0.0     0.0     1.0     0.0     1.0   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "1              0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[1 rows x 714 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Fill in the function here\n",
    "    df_copy = df.drop_duplicates(subset=['article_id','user_id'])\n",
    "    \n",
    "    user_item = df_copy.groupby(['user_id','article_id'])['title'].count().unstack()\n",
    "    \n",
    "    user_item.fillna(0, inplace=True)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)\n",
    "user_item.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.449217Z",
     "start_time": "2019-09-20T03:36:06.444231Z"
    }
   },
   "outputs": [],
   "source": [
    "## want to add n para for simple use\n",
    "## drop for assert code block \n",
    "'''\n",
    "def find_similar_users(user_id, n, user_item=user_item):\n",
    "'''\n",
    "'''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "'''\n",
    "'''\n",
    "    \n",
    "    # get user index\n",
    "    user_index = list(user_item.index.values)\n",
    "    #user_index = df.user_id.unique()\n",
    "    \n",
    "    # get user data\n",
    "    ## user_item_value = np.array(user_item.iloc[user_id,:])\n",
    "    ## upper code shape not matchprint(user_item_value)\n",
    "    user_item_value = np.array(user_item[user_item.index==user_id])\n",
    "\n",
    "    # dot product\n",
    "    dot_product = np.dot(user_item_value, np.array(user_item).T)[0]\n",
    "    dot_product = pd.Series(dot_product, index=user_index)\n",
    "    \n",
    "    # remove id\n",
    "    dot_product.drop(labels=[user_id], inplace=True)\n",
    "\n",
    "    # sorting\n",
    "    dot_product = dot_product.sort_values(ascending=False)\n",
    "   \n",
    "    # generate list\n",
    "    most_similar_users = dot_product.index.values.tolist()\n",
    "       \n",
    "    return most_similar_users[:n] # return a list of the users in order from most to least similar\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.458193Z",
     "start_time": "2019-09-20T03:36:06.451212Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    '''\n",
    "\n",
    "    # get user index\n",
    "    user_index = list(user_item.index.values)\n",
    "    #user_index = df.user_id.unique()\n",
    "    \n",
    "    # get user data\n",
    "    ## user_item_value = np.array(user_item.iloc[user_id,:])\n",
    "    ## upper code shape not matchprint(user_item_value)\n",
    "    user_item_value = np.array(user_item[user_item.index==user_id])\n",
    "\n",
    "    # dot product\n",
    "    dot_product = np.dot(user_item_value, np.array(user_item).T)[0]\n",
    "    dot_product = pd.Series(dot_product, index=user_index)\n",
    "    \n",
    "    # remove id\n",
    "    dot_product.drop(labels=[user_id], inplace=True)\n",
    "\n",
    "    # sorting\n",
    "    dot_product = dot_product.sort_values(ascending=False)\n",
    "   \n",
    "    # generate list\n",
    "    most_similar_users = dot_product.index.values.tolist()\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.466172Z",
     "start_time": "2019-09-20T03:36:06.459191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do a spot check of your function\n",
    "## alter a para with n to more \n",
    "## drop for assert\n",
    "'''\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(2,10)))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933,5)))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46,3)))\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.514045Z",
     "start_time": "2019-09-20T03:36:06.467169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 4201, 46, 3697]\n",
      "The 5 most similar users to user 3933 are: [1, 3782, 23, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` 创建了为每个用户提供最相似用户的函数后，你需要使用这些用户查找可以推荐的文章。完成以下函数，以返回向每个用户推荐的文章。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.533990Z",
     "start_time": "2019-09-20T03:36:06.515042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3933      Brunel: Imitation Is A Sincere Form Of Flattery\n",
       "23      Access Db2 Warehouse On Cloud And Db2 With Python\n",
       "3782          Airbnb Data For Analytics: Toronto Calendar\n",
       "203     10 Must Attend Data Science, Ml And Ai Confere...\n",
       "4459    Finding Optimal Locations Of New Store Using D...\n",
       "3870    Why You Should Master R (Even If It Might Even...\n",
       "131              Data Visualization With R: Scrum Metrics\n",
       "4201         Healthcare Python Streaming Application Demo\n",
       "46                               Uci: Sms Spam Collection\n",
       "3697          Flexdashboard: Interactive Dashboards For R\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code\n",
    "article_ids = find_similar_users(1)[:10]\n",
    "df.iloc[article_ids,:]['title'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:52:50.331841Z",
     "start_time": "2019-09-20T03:52:50.325857Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    ## assert require not change title\n",
    "    #article_names = list(df.iloc[article_id,:]['title'].str.title())\n",
    "    \n",
    "    # get article index to list type float\n",
    "    article_index = list(map(float, article_ids))\n",
    "    \n",
    "    # rearrange df by index\n",
    "    df_new = df.drop_duplicates(subset='article_id')[['article_id', 'title']].set_index('article_id')\n",
    "    \n",
    "    # get article name\n",
    "    article_names_ori = df_new.loc[article_index]['title'].values.tolist()\n",
    "    \n",
    "    # to remove str\n",
    "    article_names = []\n",
    "    for name in article_names_ori:\n",
    "        try:\n",
    "            name = name.replace(\"\\nName: title, dtype: object\", \"\")\n",
    "        except:\n",
    "            continue\n",
    "        article_names.append(name)\n",
    "    \n",
    "    ## archive\n",
    "    #article_ids = article_index.index[name_index].values.tolist()\n",
    "    #article_names = list(df.iloc[article_ids,:]['title'])\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:52:51.211897Z",
     "start_time": "2019-09-20T03:52:51.206925Z"
    }
   },
   "outputs": [],
   "source": [
    "# -> get_article_names\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    \n",
    "    # select user series\n",
    "    # 选中给定 id 的数据\n",
    "    user_series = user_item.loc[user_id]\n",
    "    \n",
    "    # extract user article index\n",
    "    # 检查数据观察那些文章交互过（文章的index）\n",
    "    name_index = np.where(user_series == 1)\n",
    "    \n",
    "    # match index to value (be attention also is int like), convert to list\n",
    "    # 对应上文章的编号（value）\n",
    "    article_ids = user_series.index[name_index].values.tolist()\n",
    "    \n",
    "    # get article name on article_ids\n",
    "    # 根据文章编号寻找名字\n",
    "    article_names = get_article_names(article_ids)\n",
    "    \n",
    "    return article_ids, article_names # return the ids and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:52:52.571324Z",
     "start_time": "2019-09-20T03:52:52.566782Z"
    }
   },
   "outputs": [],
   "source": [
    "# -> find_similar_users\n",
    "# -> get_user_articles\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    ## create list\n",
    "    recs= []\n",
    "    \n",
    "    ## get similar user (take m user for m output for less compute)\n",
    "    similar_user = find_similar_users(user_id)\n",
    "    #similar_user = find_similar_users(user_id)[:m]\n",
    "    \n",
    "    for user in similar_user:\n",
    "        ## get similar user's article\n",
    "        simi_index, simi_name = get_user_articles(user)\n",
    "        \n",
    "        ## get user's seen article\n",
    "        seen_index, seen_name = get_user_articles(user_id)\n",
    "        \n",
    "        ## similar minus seen\n",
    "        select_index = np.setdiff1d(np.array(simi_index),np.array(seen_index), assume_unique=True)\n",
    "        \n",
    "        ## write data\n",
    "        recs.extend(select_index.tolist())\n",
    "        \n",
    "        ## break if enough\n",
    "        if len(recs) >= m:\n",
    "            break\n",
    "    \n",
    "    # change int to str\n",
    "    #recs = list(map(str, recs))\n",
    "    \n",
    "    return recs[:m] # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:52:55.660773Z",
     "start_time": "2019-09-20T03:52:55.590962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 12.0, 14.0, 16.0, 26.0, 28.0, 29.0, 33.0, 50.0, 74.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['this week in data science (april 18, 2017)',\n",
       " 'timeseries data analysis of iot events by using jupyter notebook',\n",
       " 'got zip code data? prep it for analytics. – ibm watson data lab – medium']"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "display(user_user_recs(1, 10))\n",
    "get_article_names(user_user_recs(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:52:57.373618Z",
     "start_time": "2019-09-20T03:52:57.358660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing (2015): united states demographic measures',\n",
       " 'self-service data preparation with ibm data refinery',\n",
       " 'use the cloudant-spark connector in python notebook']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['housing (2015): united states demographic measures',\n",
       " 'self-service data preparation with ibm data refinery',\n",
       " 'use the cloudant-spark connector in python notebook']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test code\n",
    "## both int and str are acceptable\n",
    "display(get_article_names(['1320.0', '232.0', '844.0']))\n",
    "display(get_article_names([1320.0, 232.0, 844.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:53:08.238873Z",
     "start_time": "2019-09-20T03:53:08.205963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "#assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[0]) == set([1320.0, 232.0, 844.0])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "#assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[0]) == set([1024.0, 1176.0, 1305.0, 1314.0, 1422.0, 1427.0])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 现在我们将提高上述 **user_user_recs** 函数的一致性。  \n",
    "\n",
    "* 当所有用户与给定用户的邻近程度都一样时，我们并非随意选择用户，而是先选择总互动次数最多的用户，然后选择互动次数第二多的用户。\n",
    "\n",
    "\n",
    "* 当推荐的文章数量以低于 m 的数字开始并以高于 m的数字结束时，我们并非随意选择文章，而是先选择总互动次数最多的文章，然后选择总互动次数第二多的文章。你可以利用之前编写的 **top_articles** 函数获得这种排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T00:25:08.881923Z",
     "start_time": "2019-09-22T00:25:08.871923Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    ## get user index\n",
    "    user_index = list(user_item.index.values)\n",
    "    #user_index = df.user_id.unique()\n",
    "    \n",
    "    ## get user data\n",
    "    #user_item_value = np.array(user_item.iloc[user_id,:])\n",
    "    #upper code shape not matchprint(user_item_value)\n",
    "    user_item_value = np.array(user_item[user_item.index==user_id])\n",
    "\n",
    "    ## dot product\n",
    "    dot_product = np.dot(user_item_value, np.array(user_item).T)[0]\n",
    "    dot_product = pd.Series(dot_product, index=user_index)\n",
    "    \n",
    "    ## count interact\n",
    "    interact_df = df.groupby(['user_id'])['article_id'].count()\n",
    "    interact_count = interact_df.loc[user_index]\n",
    "    \n",
    "    neighbors_df = pd.DataFrame({'neighbor_id':user_index,\\\n",
    "                                 'simi':dot_product,\\\n",
    "                                 'interact_count':interact_count}).set_index('neighbor_id')\n",
    "    \n",
    "    ## remove current user from dataframe\n",
    "    neighbors_df.drop([user_id], inplace=True)\n",
    "    \n",
    "    ## sort by similarity and then by number of interactions\n",
    "    neighbors_df.sort_values(['simi', 'interact_count'], ascending=[False, False], inplace=True)\n",
    "    \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    ## create list\n",
    "    recs= []\n",
    "    \n",
    "    ## get similar user (take m user for m output for less compute)\n",
    "    top_user = get_top_sorted_users(user_id)\n",
    "    user_index = top_user.index.values\n",
    "    \n",
    "    ## rank articles on interact\n",
    "    article_rank = df.groupby(['article_id'])['user_id'].count()\n",
    "    \n",
    "    for user in user_index:\n",
    "        ## get similar user's article\n",
    "        simi_index, simi_name = get_user_articles(user)\n",
    "        \n",
    "        ## get user's seen article\n",
    "        seen_index, seen_name = get_user_articles(user_id)\n",
    "        \n",
    "        ## similar minus seen\n",
    "        select_index = np.setdiff1d(np.array(simi_index),np.array(seen_index), assume_unique=True)\n",
    "        \n",
    "        ## sort recommended articles by amount of interaction\n",
    "        sorted_article = article_rank.loc[select_index].sort_values(ascending=False).index.values.tolist()\n",
    "        \n",
    "        ## write data\n",
    "        recs.extend(sorted_article)\n",
    "        \n",
    "        ## break if enough\n",
    "        if len(recs) >= m:\n",
    "            break\n",
    "            \n",
    "    ## get output\n",
    "    recs = recs[:m]\n",
    "    \n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T00:25:09.273075Z",
     "start_time": "2019-09-22T00:25:09.230214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "[1330.0, 1427.0, 1364.0, 1170.0, 1162.0, 1304.0, 1351.0, 1160.0, 1354.0, 1368.0]\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'model bike sharing data with spss', 'analyze accident reports on amazon emr spark', 'movie recommender system with spark machine learning', 'putting a human face on machine learning']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` 请利用上述函数正确填写以下字典。然后对照解答检验该字典。按照以下注释提供必要的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T00:29:46.896440Z",
     "start_time": "2019-09-22T00:29:46.846573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simi</th>\n",
       "      <th>interact_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbor_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>35.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>17.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>15.0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             simi  interact_count\n",
       "neighbor_id                      \n",
       "3933         35.0              45\n",
       "23           17.0             364\n",
       "3782         17.0             363\n",
       "203          15.0             160\n",
       "4459         15.0             158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simi</th>\n",
       "      <th>interact_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbor_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>74.0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>39.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>33.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>33.0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>29.0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>29.0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>29.0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>29.0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>25.0</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             simi  interact_count\n",
       "neighbor_id                      \n",
       "3870         74.0             144\n",
       "3782         39.0             363\n",
       "23           38.0             364\n",
       "203          33.0             160\n",
       "4459         33.0             158\n",
       "98           29.0             170\n",
       "3764         29.0             169\n",
       "49           29.0             147\n",
       "3697         29.0             145\n",
       "242          25.0             148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check answers\n",
    "display(get_top_sorted_users(1).head())\n",
    "#display(get_top_sorted_users(131).iloc[10,:])\n",
    "display(get_top_sorted_users(131).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T00:29:55.034641Z",
     "start_time": "2019-09-22T00:29:55.030652Z"
    }
   },
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "user1_most_sim = 3933 # Find the user that is most similar to user 1 \n",
    "user131_10th_sim = 242 # Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T00:29:55.467210Z",
     "start_time": "2019-09-22T00:29:55.463222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` 如果是新用户，你可以使用上述哪个函数做出推荐？请解释。你能想到更好的推荐方法吗？在以下单元格中解释向新用户做出推荐的更好方法。\n",
    "\n",
    "**请在此处填写答案。**\n",
    "\n",
    "`7.` 利用现有函数向以下新用户提供前 10 篇推荐文章。你可以对照我们的解答测试你的函数，确保在如何做出推荐方面与我们的想法一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T02:20:03.820821Z",
     "start_time": "2019-09-22T02:20:03.814301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1429.0,\n",
       " 1330.0,\n",
       " 1431.0,\n",
       " 1427.0,\n",
       " 1364.0,\n",
       " 1314.0,\n",
       " 1293.0,\n",
       " 1170.0,\n",
       " 1162.0,\n",
       " 1304.0]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = new_user_recs = get_top_article_ids(10) # Your recommendations here\n",
    "new_user_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /Question2/ \n",
    "I can not run through this test last question, need instructions, thanks!\n",
    "- my value is 1429(first)\n",
    "- assert want 1314(first)\n",
    "- solution code are above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T03:18:37.760095Z",
     "start_time": "2019-09-22T03:18:37.751146Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-414-180cf1c05a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_user_recs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1314.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1429.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1293.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1427.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1162.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1364.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1304.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1170.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1431.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1330.0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"That's right!  Nice job!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users."
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Content-Recs\">第四部分：基于内容的推荐方法（选修内容）</a>\n",
    "\n",
    "另一种推荐方法是对与某个术语相关的文章进行从高到低排名。内容可以是 **doc_body**、**doc_description** 或**doc_full_name**。创建基于内容的推荐系统并非只有一种方式，尤其是考虑到每列都包含与内容相关的信息。  \n",
    "\n",
    "`1.` 使用以下函数主体创建一个基于内容的推荐系统。由于这个推荐系统的正确答案不止一个，所以没有提供测试函数。如果你想尝试一种需要更多输入值的方法，可以更改函数输入。当前的输入值考虑到了你可能会使用基于内容的推荐方法。此外，你可能会使用满足“内容标准”的最热门推荐方法，总之，你在做出这些推荐时可以灵活选择方法。\n",
    "\n",
    "### 这部分并非通过项目必须完成的任务。但是，你可以借机展示你的技能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.732460Z",
     "start_time": "2019-09-20T03:36:05.082Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_content_recs():\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 你已经创建了基于内容的推荐系统，接着在以下单元格中简要说明下这一基于内容的推荐系统是如何运行的。你觉得你的函数有哪些值得改进的地方吗？这一基于内容的推荐系统有什么新奇的地方吗？\n",
    "\n",
    "### 这部分并非通过项目必须完成的任务。但是，你可以借机展示你的技能。\n",
    "\n",
    "**在此处解释下这一基于内容的推荐系统。**\n",
    "\n",
    "`3.` 根据注释使用这一基于内容的推荐系统对以下情形做出推荐。我们没有提供测试，因为在创建此基于内容的推荐系统时，可以有多个正确答案。\n",
    "\n",
    "### 这部分并非通过项目必须完成的任务。但是，你可以借机展示你的技能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.733458Z",
     "start_time": "2019-09-20T03:36:05.087Z"
    }
   },
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Matrix-Fact\">第五部分：矩阵分解</a>\n",
    "\n",
    "在此部分，你将利用矩阵分解向 IBM Watson Studio 平台上的用户推荐文章。\n",
    "\n",
    "`1.` 你在上述**第三部分**的**第一个问题**中已经创建了 **user_item** 矩阵。接下来的第一个问题需要你运行单元格，为**第五部分**的其他步骤做好准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.734455Z",
     "start_time": "2019-09-20T03:36:05.091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.735452Z",
     "start_time": "2019-09-20T03:36:05.094Z"
    }
   },
   "outputs": [],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 在此部分，你可以对用户-项目矩阵运用[numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) 的奇异值分解方法。在单元格中执行 SVD，并解释为何与课程中的步骤不一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.736449Z",
     "start_time": "2019-09-20T03:36:05.098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = # use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在此处填写答案。**\n",
    "\n",
    "`3.` 如何确定潜在特征的数量？这个问题比较难。运行以下单元格后你会发现，随着潜在特征数量的增加，用户-项目矩阵中 1 和 0 值的预测错误率会降低。运行以下单元格，了解当潜在特征的数量增加时，准确率会如何提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.737447Z",
     "start_time": "2019-09-20T03:36:05.101Z"
    }
   },
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 通过上述单元格，我们无法判断要使用多少个潜在特征，因为能够更好地预测矩阵的 1 和 0 值，并不表明我们就能做出很好的推荐。我们可以将数据集划分为训练集和测试集，如以下单元格所示。  \n",
    "\n",
    "根据第三个问题的代码判断，不同的潜在特征数量对训练集和测试集的准确率有何影响。使用以下划分方法： \n",
    "\n",
    "* 我们可以对测试集中的多少个用户做出预测？  \n",
    "* 由于冷启动问题，我们无法对多少个用户做出预测？\n",
    "* 我们可以对测试集中的多少篇文章做出预测？  \n",
    "* 由于冷启动问题，我们无法对多少篇文章做出预测？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.738444Z",
     "start_time": "2019-09-20T03:36:05.105Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.738444Z",
     "start_time": "2019-09-20T03:36:05.108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': # letter here, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': # letter here, \n",
    "    'How many articles can we make predictions for in the test set?': # letter here,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?': # letter here\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` 现在对上述 **user_item_train** 数据集进行奇异值分解，并得出 U、S 和 V 转置矩阵。然后判断在使用不同的潜在特征数量时，可以使用此矩阵分解方法对 **user_item_test** 数据集中的多少行做出预测，并根据测试数据的准确率确定应该保留多少个潜在特征。这个问题需要运用在第 `2` - `4`.个问题中完成的步骤。\n",
    "\n",
    "通过以下单元格了解 SVD 在测试数据上做出推荐预测的效果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.739441Z",
     "start_time": "2019-09-20T03:36:05.112Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = # fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T03:36:06.740439Z",
     "start_time": "2019-09-20T03:36:05.114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` 在以下单元格中解释上个问题的结果。根据你得出的结果，讨论下你会如何判断上述推荐系统是否比用户目前查找文章的方式更好。 \n",
    "\n",
    "**请在此处填写答案。**\n",
    "\n",
    "<a id='conclusions'></a>\n",
    "## 其他内容\n",
    "你现在可以保存为每个用户推荐的文章，开发一个类来作出新的预测并更新结果，以及创建一个部署结果的应用。这些任务并不是此项目必须完成的任务。但是，在学完课程知识后，你肯定能够继续完成这些任务并改进你的项目。\n",
    "\n",
    "\n",
    "# 总结\n",
    "\n",
    "> 恭喜！你已经完成 IBM 推荐系统项目。 \n",
    "\n",
    "> **小贴士**：当你对项目满意后，请检查报告并看看是否满足所有[审阅标准](https://review.udacity.com/#!/rubrics/2632/view)。请删除所有的**小贴士**（例如上方小贴士），使演示尽可能流畅。\n",
    "\n",
    "\n",
    "# 提交指南\n",
    "\n",
    "> 在提交项目之前，你需要在 workspace 的此部分创建 notebook 的 .html 或 .pdf 版本。运行以下单元格即可创建这两种版本。如果操作正确，系统会返回代码 0，并且你可以在 workspace 目录（点击左上角的橙色 Jupyter 图标）中看到生成的 .html 文件。\n",
    "\n",
    "> 或者，你可以通过**文件** > **下载为**子菜单将此报告下载为 .html 文件，然后手动将报告上传到 workspace 目录中：点击左上角的橙色 Jupyter 图标，然后点击“上传”按钮。\n",
    "\n",
    "> 完成这些步骤后，你可以点击右下角的“提交项目”按钮，提交项目。这样便会创建和提交一个 zip 文件，其中包含此 .ipynb 文件和你创建的 .html 或 .pdf 文件。恭喜！ \n",
    "\n",
    "\n",
    "```python\n",
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
