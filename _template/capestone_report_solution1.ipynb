{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capestone Project Solution1\n",
    "## / Toxic Comment Classification /\n",
    "\n",
    "- - -\n",
    "<ul>\n",
    "<li><a href=\"#prepare\">I 环境准备</a></li>\n",
    "<li><a href=\"#wrangling\">II 向量化</a></li>\n",
    "<li><a href=\"#eda\">III 评分</a></li>\n",
    "<li><a href=\"#conclusions\">IV 结论</a></li>\n",
    "</ul>\n",
    "\n",
    "<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id='prepare'>I 环境准备</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prpare env \n",
    "\n",
    "# 用这个框对你计划使用的所有数据包进行设置\n",
    "# 导入语句\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置参数显示长文本\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "# 行内显示\n",
    "%matplotlib inline\n",
    "\n",
    "# 机器学习库\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "## found utf8 content\n",
    "## -1 是可能的选择，0为非攻击性语言\n",
    "\n",
    "test_labels = pd.read_csv('test_labels.csv')\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "## 1 是标记为恶毒的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  00001cee341fdb12   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      comment_text  \n",
       "0  Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check files\n",
    "\n",
    "test.head(1)\n",
    "## 注意第6行是良好评论数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head(1)\n",
    "## 注意在test_labels中，提示了良好评论的分类（全为0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  0000997932d777bf   \n",
       "\n",
       "                                                                                                                                                                                                                                                                comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)\n",
    "## 注意第7行是train的目标数据处理结果\n",
    "## 将涉及到的负面类型通过1来标记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id='wrangling'>II 向量化</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize\n",
    "\n",
    "## set classes\n",
    "class_list = list(train.columns[2:])\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get comment\n",
    "train_comment = train.comment_text\n",
    "test_comment = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vectorizer\n",
    "\n",
    "## set comment vectorizer\n",
    "comment_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    ## 表示只拆解1个单词，如果是(1:2)表示拆解1-2个单词\n",
    "    ## https://stackoverflow.com/questions/24005762/understanding-the-ngram-range-argument-in-a-countvectorizer-in-sklearn\n",
    "    max_features=10000)\n",
    "\n",
    "## fit comment vectorizer\n",
    "comment_vectorizer.fit(train_comment)\n",
    "\n",
    "## get train and test comment featrues\n",
    "train_comment_features = comment_vectorizer.transform(train_comment)\n",
    "test_comment_features = comment_vectorizer.transform(test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 10000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check comment out put\n",
    "train_comment_features.shape\n",
    "##  输出是所有单词在1w个向量上的得分，每个数据是这样的：\n",
    "##  (0, 9974)\t0.21031181661230514\n",
    "## 说明第0号词，在9974分类向量的概率为 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set ngram vectorizer\n",
    "character_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 4),\n",
    "    ## 标识对应 2到4个字母的组合\n",
    "    max_features=50000)\n",
    "\n",
    "## fit character vectorizer\n",
    "character_vectorizer.fit(train_comment)\n",
    "\n",
    "## get train and test ngram featrues\n",
    "train_character_features = character_vectorizer.transform(train_comment)\n",
    "test_character_features = character_vectorizer.transform(test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 60000)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check features with both word and character (train)\n",
    "train_features = hstack([train_comment_features, train_character_features])\n",
    "train_features.shape\n",
    "## 可以看出对于每个评论，featrues 输出为 1w word + 5w ngram = 6w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 60000)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check features with both word and character (test)\n",
    "test_features = hstack([test_comment_features, test_character_features])\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id='eda'>III 评分</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(training) Class toxic Score : 0.971520588226553\n",
      "(training) Class severe_toxic Score : 0.9876289384719945\n",
      "(training) Class obscene Score : 0.9860771390906266\n",
      "(training) Class threat Score : 0.9835028550329452\n",
      "(training) Class insult Score : 0.97875904830758\n",
      "(training) Class identity_hate Score : 0.9752953024910692\n"
     ]
    }
   ],
   "source": [
    "# 评分\n",
    "\n",
    "## 建立评分列表\n",
    "score_list = []\n",
    "\n",
    "## 根据submission sample定义 submission格式\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "## 定义 classifier\n",
    "classifier = LogisticRegression(C=0.1, solver='sag')\n",
    "\n",
    "## 循环每一个分类\n",
    "for name in class_list:\n",
    "    # 获取当前分类数据\n",
    "    train_target = train[name]\n",
    "    \n",
    "    # fit classifier\n",
    "    classifier.fit(train_features, train_target)\n",
    "    \n",
    "    # 计算 training score\n",
    "    score = np.mean(cross_val_score(classifier, train_features, train_target, scoring='roc_auc', cv=5))\n",
    "    ## 新版本的默认 cv 已经从3变为5，手动设定5，保持一致\n",
    "\n",
    "    # 将 score 写入 score_list\n",
    "    score_list.append(score)\n",
    "    # 输出 score\n",
    "    print('(training) Class {} Score : {}'.format(name, cv_score))\n",
    "    \n",
    "    # 使用 classier 输出 test 的结果\n",
    "    submission[name] = classifier.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(training) Average Class Score: 0.980464041358258)\n"
     ]
    }
   ],
   "source": [
    "# get finial score\n",
    "print('(training) Average Class Score: {})'.format(np.mean(score_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id='conclusions'>IV 结论</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: output file saved as submission_s1.csv\n"
     ]
    }
   ],
   "source": [
    "# output submission\n",
    "filename = 'submission_s1.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "print('Complete: output file saved as {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 主要参考资料：\n",
    "1. [项目建议中的LR + 词袋模式](https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams)\n",
    "2. [Cross-validation Performance](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)\n",
    "\n",
    "> 小结：\n",
    "1. Solution1 为 LR + CBOW 的方式进行多分类计算\n",
    "2. 输出结果是每个分类的可能性[0,1]\n",
    "\n",
    "> Kaggle Score:\n",
    "1. 0.97576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
